{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0406d30",
   "metadata": {},
   "source": [
    "# CNN INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bde322",
   "metadata": {},
   "source": [
    "* CNN Stands For Convolution Neural Network It Is A Type Of Deep Learning Model Specially Used For Image Data, It Can Perform Tasks Like Image Recognition, Object Detection, Face Recognition etc. Unlike Decision Tree Classifier Which Is Trained On CSV Data CNN's Are Trained On Images And Image Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca4f2c0",
   "metadata": {},
   "source": [
    "* Let Us Begin With The Handwritten Digit Recognition With Dataset Included With TensorFlow, Where TensorFlow Is A Library Used For Implementing And Training CNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077af71",
   "metadata": {},
   "source": [
    "* Let Us First Install Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973dbc7f",
   "metadata": {},
   "source": [
    "* Importing Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e9299",
   "metadata": {},
   "source": [
    "* Keras Is A Tool In Tensorflow To Simplify The Process Of DeepLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7020ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86b978",
   "metadata": {},
   "source": [
    "* Loading And Processing mnist Dataset where mnist Is A Dataset Which Consists Of Large Dataset Of Handwritten Digits For Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28753de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Fetching Train And Test Datasets \n",
    "(train_images,train_labels),(test_images,test_labels)=datasets.mnist.load_data()\n",
    "\n",
    "#Normalizing The Pixel Value Between 0-1, Since The Pixel Coloration Value Ranges From 0(Black) To 255(White) hence dividing any value from between 0 to 255 would yield result between 0 to 1\n",
    "train_images=train_images/255.0\n",
    "test_images=train_images/255.0\n",
    "\n",
    "#Reshaping The Images \n",
    "# .reshape((dataset_size,width,height,channel_layers)), where channel_layers refer to layers In The Image In Case Of GrayScale Images it is \"1\" And In Case Of RGB Images It Is \"3\"\n",
    "train_images=train_images.reshape((-1,28,28,1)) #where -1 refers let the model itself identify the size of dataset\n",
    "test_images=test_images.reshape((-1,28,28,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad419d82",
   "metadata": {},
   "source": [
    "* Building The CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0560f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=models.Sequential([\n",
    "    #Applying 32 filters on the image to understand the edges, lines in the images by scanning a image of size 28x28 by 3x3 size of filter\n",
    "    # the function relu finds the maximum i.e darkest pixels in the image relu(x)=max(0,x) \n",
    "    layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    #maxpooling2D highlights the darker i.e important parts in the image into 2x2 pixel frame\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    #Applying 64 filters on the image to understand the curves,loops in the images by scanning a image of size 28x28 by 3x3 size of filter\n",
    "    layers.Conv2D(64,(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    #Converting a 2D image into 1D assume it as converting a 2x2 matrix into list of 4 elements\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Creating a layer on dense neurons out of which each's output would be influenced by previous layer\n",
    "    # passes raw scores\n",
    "    layers.Dense(64,activation='relu'),\n",
    "\n",
    "    # softmax converts this soft scores into probabilities and the number with highest probability is the predicted number\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b1745",
   "metadata": {},
   "source": [
    "* Compiling The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d46ee092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d5bb8",
   "metadata": {},
   "source": [
    "* Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5a85b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9039 - loss: 0.3247 - val_accuracy: 0.9855 - val_loss: 0.0497\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0494 - val_accuracy: 0.9860 - val_loss: 0.0467\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.0342 - val_accuracy: 0.9882 - val_loss: 0.0406\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0219 - val_accuracy: 0.9913 - val_loss: 0.0298\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0162 - val_accuracy: 0.9900 - val_loss: 0.0370\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=5, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
